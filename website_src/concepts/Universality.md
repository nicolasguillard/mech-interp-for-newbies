# Universality

>[!quote] from "[Mechanistic Interpretability for AI Safety A Review](https://leonardbereska.github.io/blog/2024/mechinterpreview/)" [[References#^7739fa|(Bereska and al. - 2024)]]
>***Weak universality*** : There are underlying principles governing how neural networks learn to solve certain tasks. Models will generally converge on analogous solutions that adhere to the common underlying principles. However, the specific [[Feature|features]] and [[Circuit|circuits]] that implement these principles can vary across different models based on factors like hyperparameters, random seeds, and architectural choices.
>
>***Strong Universality*** : The same core features and circuits will universally and consistently arise across all neural network models trained on similar tasks and data distributions and using similar techniques, reflecting a set of fundamental computational motifs that neural networks inherently gravitate towards when learning.