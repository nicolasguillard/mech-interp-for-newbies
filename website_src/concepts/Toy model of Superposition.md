# Toy model of Superposition

>[!quote] from "[Mechanistic Interpretability for AI Safety A Review](https://leonardbereska.github.io/blog/2024/mechinterpreview/)" [[References#^7739fa|(Bereska and al. - 2024)]]
>A toy model investigates the hypothesis that neural networks can represent more [[Feature|features]] than the number of [[Neuron|neurons]] by encoding real-world [[Concept|concepts]] in a compressed manner.