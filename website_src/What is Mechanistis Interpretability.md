# What is Mechanistis Interpretability ?

## Définition
>[!quote] from "[Introduction to Mechanistic Interpretability](https://aisafetyfundamentals.com/blog/introduction-to-mechanistic-interpretability)" [[References#^e24a21|(Sarah Hastings-Woodhouse - AI Safety Fundamentals - 08/2024)]]
>Mechanistic Interpretability is an emerging field that seeks to **understand the internal reasoning processes of trained neural networks** and gain insight into how and why they produce the outputs that they do. AI researchers currently have very little understanding of what is happening inside state-of-the-art models.

>[!quote] from "[Mechanistic Interpretability for AI Safety A Review](https://leonardbereska.github.io/blog/2024/mechinterpreview/)" [[References#^7739fa|(Bereska and al. - 2024)]]
>Reverse engineering the computational mechanisms and representations learned by neural networks into human-understandable algorithms and concepts to provide a granular, causal understanding.

>[!quote] from "[A Comprehensive Mechanistic Interpretability Explainer & Glossary](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=eL6tFQqNwd4LbYlO1DVIen8K)" [[References#^d1d4d1|(Neel Nanda - 12/2022)]]
>The field of study of reverse engineering neural networks from the learned weights down to human-interpretable algorithms. Analogous to reverse engineering a compiled program binary back to source code.

>[!quote] from "[Mechanistic Interpretability, Variables, and the Importance of Interpretable Bases](https://transformer-circuits.pub/2022/mech-interp-essay/index.html)" [[References#^05ff7e|(Chris Olah - Transformer Circuits Thread - Anthropic 06/2022)]]
>Mechanistic interpretability seeks to reverse engineer neural networks, similar to how one might reverse engineer a compiled binary computer program.

## The main concepts
1. [[Neuron]]
2. [[Feature]]
3. [[Concept]]
4. [[Representation of Features]]
5. [[Decomposability]]
6. [[Circuit]]
7. [[End-to-end circuit]]
8. [[Circuits As Computational Subgraphs]]
9. [[Transformer Circuits]]
10. [[Direct Path term Circuit]]
11. [[QK-Circuit]]
12. [[OV-Circuit]]
13. [[Induction Circuit]]
14. [[Induction head]]
15. [[Duplicate token head]]
16. [[The Indirect Object Identification Circuit]]
17. [[Universality]]
18. [[Motif]]
19. [[Superposition]]
20. [[Toy model of Superposition]]
21. [[Bottleneck superposition]]
22. [[Neuron superposition]]
23. [[Neuron polysemanticity]]
24. [[Neuron monosemanticity]]
